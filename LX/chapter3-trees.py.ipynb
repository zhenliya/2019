{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算给定数据集的香农熵\n",
    "def calcShannonEnt(dataSet):\n",
    "    #计算数据集中的实例总数\n",
    "    numEntries=len(dataSet)\n",
    "    #分类字典（key:分类名称 value:数量）\n",
    "    labelCounts={}\n",
    "    #遍历数据集，将分类名称，数量添加到分类字典中\n",
    "    for featVec in dataSet:\n",
    "        currentLabel=featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel]=0\n",
    "        labelCounts[currentLabel]+=1\n",
    "    shannonEnt=0.0\n",
    "    #计算所有类别的期望值总和\n",
    "    for key in labelCounts:\n",
    "        #类别发生频率\n",
    "        prob=float(labelCounts[key])/numEntries\n",
    "        shannonEnt-=prob*log(prob,2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建数据集\n",
    "def createDataSet():\n",
    "    dataSet=[[1,1,'yes'],[1,1,'yes'],[1,0,'no'],[0,1,'no'],[0,1,'no']]\n",
    "    labels=['no surfacing','flippers']\n",
    "    return dataSet,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按照给定特征划分数据集(dataSet:待划分数据集 axis:划分数据集特征 value:特征返回值)\n",
    "def splitDataSet(dataSet,axis,value):\n",
    "    #创建新的列表对象，用于保存划分后的数据集\n",
    "    retDataSet=[]\n",
    "    #遍历数据集中的每个元素，一旦发现符合要求的值，将其添加到新创建的列表中\n",
    "    for featVec in dataSet:\n",
    "        #将符合特征的数据抽取出来\n",
    "        if featVec[axis]==value:\n",
    "            reducedFeatVec=featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#选择最好的数据集划分方式\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "        #当前数据集包含的特征属性数量\n",
    "        numFeatures=len(dataSet[0])-1\n",
    "        #计算整个数据集的香农熵\n",
    "        baseEntropy=calcShannonEnt(dataSet)\n",
    "        bestInfoGain=0.0;bestFeature=-1\n",
    "        #遍历数据集中的所有特征值\n",
    "        for i in range(numFeatures):\n",
    "            #将数据集中所有第i个特征值或者可能存在的值写入列表\n",
    "            featList=[example[i] for example in dataSet]\n",
    "            #使用列表创建集合（可过滤掉重复的元素）\n",
    "            uniqueVals=set(featList)\n",
    "            newEntropy=0.0\n",
    "            for value in uniqueVals:\n",
    "                subDataSet=splitDataSet(dataSet,i,value)\n",
    "                prob=len(subDataSet)/float(len(dataSet))\n",
    "                newEntropy+=prob*calcShannonEnt(subDataSet)\n",
    "            infoGain=baseEntropy-newEntropy\n",
    "            if (infoGain>bestInfoGain):\n",
    "                bestInfoGain=infoGain\n",
    "                bestFeature=i\n",
    "        return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorityCnt(classList):\n",
    "    classCount={}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():classCount[vote]=0\n",
    "        classCount[vote]+=1\n",
    "    shortedClassCount=shorted(classCount.iteriyems(),key=operator.itemgetter(1),reverse=True)\n",
    "    return shortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建决策树\n",
    "def createTree(dataSet,labels):\n",
    "    classList=[example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0])==len(classList):\n",
    "        return classList[0]\n",
    "    if len(dataSet[0])==1:\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat=chooseBestFeatureToSplit(dataSet)\n",
    "    bestFeatLabel=labels[bestFeat]\n",
    "    myTree={bestFeatLabel:{}}\n",
    "    del(labels[bestFeat])\n",
    "    featValues=[example[bestFeat] for example in dataSet]\n",
    "    uniqueVals=set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels=labels[:]\n",
    "        myTree[bestFeatLabel][value]=createTree(splitDataSet(dataSet,bestFeat,value),subLabels)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
