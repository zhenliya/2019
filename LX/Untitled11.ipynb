{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Null Set   1\n",
      "     z   5\n",
      "       r   1\n",
      "       x   3\n",
      "         y   3\n",
      "           s   2\n",
      "             t   2\n",
      "           r   1\n",
      "             t   1\n",
      "     x   1\n",
      "       s   1\n",
      "         r   1\n",
      "conditional tree for:  {'y'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "       x   3\n",
      "conditional tree for:  {'y', 'x'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "conditional tree for:  {'s'}\n",
      "   Null Set   1\n",
      "     x   3\n",
      "conditional tree for:  {'t'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "       y   3\n",
      "         x   3\n",
      "conditional tree for:  {'y', 't'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "conditional tree for:  {'x', 't'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "       y   3\n",
      "conditional tree for:  {'x', 'y', 't'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "conditional tree for:  {'x'}\n",
      "   Null Set   1\n",
      "     z   3\n"
     ]
    }
   ],
   "source": [
    "class treeNode:\n",
    "    def __init__(self, nameValue, numOccur, parentNode):\n",
    "        self.name = nameValue\n",
    "        self.count = numOccur\n",
    "        self.nodeLink = None\n",
    "        self.parent = parentNode      #needs to be updated\n",
    "        self.children = {} \n",
    "    \n",
    "    def inc(self, numOccur):\n",
    "        self.count += numOccur\n",
    "        \n",
    "    def disp(self, ind=1):\n",
    "        print('  '*ind, self.name, ' ', self.count)\n",
    "        for child in self.children.values():\n",
    "            child.disp(ind+1)\n",
    "\n",
    "def createTree(dataSet, minSup=1): #create FP-tree from dataset but don't mine\n",
    "    headerTable = {}\n",
    "    #go over dataSet twice\n",
    "    for trans in dataSet:#first pass counts frequency of occurance\n",
    "        for item in trans:\n",
    "            headerTable[item] = headerTable.get(item, 0) + dataSet[trans]\n",
    "    for k in list(headerTable.keys()):  #remove items not meeting minSup\n",
    "        if headerTable[k] < minSup: \n",
    "            del(headerTable[k])\n",
    "    freqItemSet = set(headerTable.keys())\n",
    "    #print 'freqItemSet: ',freqItemSet\n",
    "    if len(freqItemSet) == 0: return None, None  #if no items meet min support -->get out\n",
    "    for k in headerTable:\n",
    "        headerTable[k] = [headerTable[k], None] #reformat headerTable to use Node link \n",
    "    #print 'headerTable: ',headerTable\n",
    "    retTree = treeNode('Null Set', 1, None) #create tree\n",
    "    for tranSet, count in dataSet.items():  #go through dataset 2nd time\n",
    "        localD = {}\n",
    "        for item in tranSet:  #put transaction items in order\n",
    "            if item in freqItemSet:\n",
    "                localD[item] = headerTable[item][0]\n",
    "        if len(localD) > 0:\n",
    "            orderedItems = [v[0] for v in sorted(localD.items(), key=lambda p: p[1], reverse=True)]\n",
    "            updateTree(orderedItems, retTree, headerTable, count)#populate tree with ordered freq itemset\n",
    "    return retTree, headerTable #return tree and header table\n",
    "\n",
    "def updateTree(items, inTree, headerTable, count):\n",
    "    if items[0] in inTree.children:#check if orderedItems[0] in retTree.children\n",
    "        inTree.children[items[0]].inc(count) #incrament count\n",
    "    else:   #add items[0] to inTree.children\n",
    "        inTree.children[items[0]] = treeNode(items[0], count, inTree)\n",
    "        if headerTable[items[0]][1] == None: #update header table \n",
    "            headerTable[items[0]][1] = inTree.children[items[0]]\n",
    "        else:\n",
    "            updateHeader(headerTable[items[0]][1], inTree.children[items[0]])\n",
    "    if len(items) > 1:#call updateTree() with remaining ordered items\n",
    "        updateTree(items[1::], inTree.children[items[0]], headerTable, count)\n",
    "        \n",
    "def updateHeader(nodeToTest, targetNode):   #this version does not use recursion\n",
    "    while (nodeToTest.nodeLink != None):    #Do not use recursion to traverse a linked list!\n",
    "        nodeToTest = nodeToTest.nodeLink\n",
    "    nodeToTest.nodeLink = targetNode\n",
    "        \n",
    "def ascendTree(leafNode, prefixPath): #ascends from leaf node to root\n",
    "    if leafNode.parent != None:\n",
    "        prefixPath.append(leafNode.name)\n",
    "        ascendTree(leafNode.parent, prefixPath)\n",
    "    \n",
    "def findPrefixPath(basePat, treeNode): #treeNode comes from header table\n",
    "    condPats = {}\n",
    "    while treeNode != None:\n",
    "        prefixPath = []\n",
    "        ascendTree(treeNode, prefixPath)\n",
    "        if len(prefixPath) > 1: \n",
    "            condPats[frozenset(prefixPath[1:])] = treeNode.count\n",
    "        treeNode = treeNode.nodeLink\n",
    "    return condPats\n",
    "\n",
    "def mineTree(inTree, headerTable, minSup, preFix, freqItemList):\n",
    "   bigL = [v[0] for v in sorted(headerTable.items(), key=lambda p: p[1][0])]#(sort header table)\n",
    "   for basePat in bigL:  #start from bottom of header table\n",
    "        newFreqSet = preFix.copy()\n",
    "        newFreqSet.add(basePat)\n",
    "        #print 'finalFrequent Item: ',newFreqSet    #append to set\n",
    "        freqItemList.append(newFreqSet)\n",
    "        condPattBases = findPrefixPath(basePat, headerTable[basePat][1])\n",
    "        #print 'condPattBases :',basePat, condPattBases\n",
    "        #2. construct cond FP-tree from cond. pattern base\n",
    "        myCondTree, myHead = createTree(condPattBases, minSup)\n",
    "        #print 'head from conditional tree: ', myHead\n",
    "        if myHead != None: #3. mine cond. FP-tree\n",
    "            print('conditional tree for: ',newFreqSet)\n",
    "            myCondTree.disp(1)            \n",
    "            mineTree(myCondTree, myHead, minSup, newFreqSet, freqItemList)\n",
    "\n",
    "def loadSimpDat():\n",
    "    simpDat = [['r', 'z', 'h', 'j', 'p'],\n",
    "               ['z', 'y', 'x', 'w', 'v', 'u', 't', 's'],\n",
    "               ['z'],\n",
    "               ['r', 'x', 'n', 'o', 's'],\n",
    "               ['y', 'r', 'x', 'z', 'q', 't', 'p'],\n",
    "               ['y', 'z', 'x', 'e', 'q', 's', 't', 'm']]\n",
    "    return simpDat\n",
    "\n",
    "def createInitSet(dataSet):\n",
    "    retDict = {}\n",
    "    for trans in dataSet:\n",
    "        retDict[frozenset(trans)] = 1\n",
    "    return retDict\n",
    "\n",
    "import twitter\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "def textParse(bigString):\n",
    "    urlsRemoved = re.sub('(http:[/][/]|www.)([a-z]|[A-Z]|[0-9]|[/.]|[~])*', '', bigString)    \n",
    "    listOfTokens = re.split(r'\\W*', urlsRemoved)\n",
    "    return [tok.lower() for tok in listOfTokens if len(tok) > 2]\n",
    "\n",
    "def getLotsOfTweets(searchStr):\n",
    "    CONSUMER_KEY = ''\n",
    "    CONSUMER_SECRET = ''\n",
    "    ACCESS_TOKEN_KEY = ''\n",
    "    ACCESS_TOKEN_SECRET = ''\n",
    "    api = twitter.Api(consumer_key=CONSUMER_KEY, consumer_secret=CONSUMER_SECRET,\n",
    "                      access_token_key=ACCESS_TOKEN_KEY, \n",
    "                      access_token_secret=ACCESS_TOKEN_SECRET)\n",
    "    #you can get 1500 results 15 pages * 100 per page\n",
    "    resultsPages = []\n",
    "    searchResults = api.GetSearch(searchStr, count=100)\n",
    "    resultsPages.append(searchResults)\n",
    "    return resultsPages\n",
    "\n",
    "def mineTweets(tweetArr, minSup=5):\n",
    "    parsedList = []\n",
    "    for i in range(14):\n",
    "        for j in range(100):\n",
    "            parsedList.append(textParse(tweetArr[i][j].text))\n",
    "    initSet = createInitSet(parsedList)\n",
    "    myFPtree, myHeaderTab = createTree(initSet, minSup)\n",
    "    myFreqList = []\n",
    "    mineTree(myFPtree, myHeaderTab, minSup, set([]), myFreqList)\n",
    "    return myFreqList\n",
    "\n",
    "minSup = 3\n",
    "simpDat = loadSimpDat()\n",
    "initSet = createInitSet(simpDat)\n",
    "myFPtree, myHeaderTab = createTree(initSet, minSup)\n",
    "myFPtree.disp()\n",
    "myFreqList = []\n",
    "mineTree(myFPtree, myHeaderTab, minSup, set([]), myFreqList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TwitterError",
     "evalue": "The twitter.Api instance must be authenticated.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTwitterError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-cd7e39baa257>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlotsOtweets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetLotsOfTweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RIMM\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-72cf6f5d5e6d>\u001b[0m in \u001b[0;36mgetLotsOfTweets\u001b[1;34m(searchStr)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;31m#you can get 1500 results 15 pages * 100 per page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0mresultsPages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[0msearchResults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearchStr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m     \u001b[0mresultsPages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearchResults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresultsPages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\twitter\\api.py\u001b[0m in \u001b[0;36mGetSearch\u001b[1;34m(self, term, raw_query, geocode, since_id, max_id, until, since, count, lang, locale, result_type, include_entities, return_json)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_RequestUrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GET'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_RequestUrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GET'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ParseAndCheckTwitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\twitter\\api.py\u001b[0m in \u001b[0;36m_RequestUrl\u001b[1;34m(self, url, verb, data, json, enforce_auth)\u001b[0m\n\u001b[0;32m   4957\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0menforce_auth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__auth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4959\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTwitterError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The twitter.Api instance must be authenticated.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4961\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep_on_rate_limit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTwitterError\u001b[0m: The twitter.Api instance must be authenticated."
     ]
    }
   ],
   "source": [
    "lotsOtweets=getLotsOfTweets(\"RIMM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
